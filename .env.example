# Move37 content-summarize configuration template
# Copy this file to `.env` and replace placeholder values.
#
# Config loading contract (from tasks.md):
# 1. Only read LLM config from `.env`.
# 2. Use `LLM_PROVIDER` to select the provider block.
# 3. Read selected provider values:
#    - LLM_<PROVIDER>_API_KEY (required)
#    - LLM_<PROVIDER>_MODEL
#    - LLM_<PROVIDER>_BASE_URL
# 4. Read common runtime params for all providers:
#    - LLM_TEMPERATURE / LLM_MAX_TOKENS / LLM_TIMEOUT / LLM_MAX_RETRIES
#
# Supported values: openai | deepseek | gemini | glm
LLM_PROVIDER=openai

# Common generation settings
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2000
LLM_TIMEOUT=60
LLM_MAX_RETRIES=3

# Optional: override default prompt template.
# Must contain "{url}" placeholder.
LLM_PROMPT_TEMPLATE=

# OpenAI (used when LLM_PROVIDER=openai)
LLM_OPENAI_API_KEY=
LLM_OPENAI_MODEL=gpt-3.5-turbo
LLM_OPENAI_BASE_URL=https://api.openai.com/v1

# DeepSeek (used when LLM_PROVIDER=deepseek)
LLM_DEEPSEEK_API_KEY=
LLM_DEEPSEEK_MODEL=deepseek-chat
LLM_DEEPSEEK_BASE_URL=https://api.deepseek.com

# Gemini (used when LLM_PROVIDER=gemini)
# Gemini SDK usually does not require base_url.
# NOTE: YouTube links are always summarized by Gemini.
LLM_GEMINI_API_KEY=
LLM_GEMINI_MODEL=gemini-2.5-flash
LLM_GEMINI_BASE_URL=

# GLM (used when LLM_PROVIDER=glm)
LLM_GLM_API_KEY=
LLM_GLM_MODEL=glm-4
LLM_GLM_BASE_URL=https://open.bigmodel.cn/api/paas/v4/

# Feishu notification settings (notify-feishu)
# Use Feishu bot app credentials + chat receive id.
FEISHU_APP_ID= # 飞书机器人应用的ID
FEISHU_APP_SECRET= # 飞书机器人应用的密钥
FEISHU_CHAT_RECEIVE_ID= # 飞书群接收消息的ID
FEISHU_CHAT_RECEIVE_ID_TYPE=chat_id

# Feishu wiki settings (write-feishu-docx)
# Reuse FEISHU_APP_ID / FEISHU_APP_SECRET for auth.
FEISHU_WIKI_SPACE_ID= # 飞书知识库 Space ID
FEISHU_WIKI_PARENT_NODE_TOKEN= # 写入文档的父节点 token
