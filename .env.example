# Move37 content-summarize configuration template
# Copy this file to `.env` and replace placeholder values.
#
# Config loading contract (from tasks.md):
# 1. Only read LLM config from `.env`.
# 2. Use `LLM_PROVIDER` to select the provider block.
# 3. Read selected provider values:
#    - LLM_<PROVIDER>_API_KEY (required)
#    - LLM_<PROVIDER>_MODEL
#    - LLM_<PROVIDER>_BASE_URL
# 4. Read common runtime params for all providers:
#    - LLM_TEMPERATURE / LLM_MAX_TOKENS / LLM_TIMEOUT / LLM_MAX_RETRIES
#
# Supported values: openai | deepseek | gemini | glm
LLM_PROVIDER=openai

# Common generation settings
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2000
LLM_TIMEOUT=60
LLM_MAX_RETRIES=3

# Optional: override default prompt template.
# Must contain "{url}" placeholder.
LLM_PROMPT_TEMPLATE=

# OpenAI (used when LLM_PROVIDER=openai)
LLM_OPENAI_API_KEY=
LLM_OPENAI_MODEL=gpt-3.5-turbo
LLM_OPENAI_BASE_URL=https://api.openai.com/v1

# DeepSeek (used when LLM_PROVIDER=deepseek)
LLM_DEEPSEEK_API_KEY=
LLM_DEEPSEEK_MODEL=deepseek-chat
LLM_DEEPSEEK_BASE_URL=https://api.deepseek.com

# Gemini (used when LLM_PROVIDER=gemini)
# Gemini SDK usually does not require base_url.
# NOTE: YouTube links are always summarized by Gemini.
LLM_GEMINI_API_KEY=
LLM_GEMINI_MODEL=gemini-2.5-flash
LLM_GEMINI_BASE_URL=

# GLM (used when LLM_PROVIDER=glm)
LLM_GLM_API_KEY=
LLM_GLM_MODEL=glm-4
LLM_GLM_BASE_URL=https://open.bigmodel.cn/api/paas/v4/
